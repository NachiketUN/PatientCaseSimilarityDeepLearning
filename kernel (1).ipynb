{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.cache', '.keras', 'patient_with_reports.csv', '.config', 'MIMIC Explore V3.ipynb', 'mimic-300D-3.5M.bin', 'anaconda3', 'ChinaSet_AllFiles.zip', 'IR', 'final.csv', '.jupyter', 'text_cleaned.csv', 'model3.pth', 'PatY.pickle', 'model-mimic.bin.wv.vectors.npy', 'model-mimic.bin.trainables.syn1neg.npy', '.python_history', 'nltk_data', 'MIMIC Explore Edition Notebook.ipynb', 'MIMIC Explore V2.ipynb', '.profile', '.ipython', 'list_of_report.csv', 'model-mimic.bin', '.bashrc', 'model1.pth', 'without_prepro_model1.pth', 'PatientCombo.csv', 'FINAL INTEGRATED MODEL .ipynb', 'NewPatReportMatrix.pickle', '.bash_history', 'PatComboArr.pickle', 'adm_disease_probablity.csv', '.nano', 'model4.pth', 'text_cleaned.csv.zip', 'PatientCombo.csvC', 'kernel.ipynb', 'weights-GRU.best.hdf5', '.local', '.bash_logout', 'alexmodel1.pth', '.torch', 'ChinaSet_AllFiles', 'PatComboShuffle.pickle', '.ipynb_checkpoints', 'kernel (6).ipynb', 'Generator_keras.ipynb', 'ChestModel.ipynb', 'data', 'MIMIC EXPLORE V4.ipynb', 'weights.best.hdf5', 'mimic-300D-3.5M.bin.wv.vectors.npy', '.nv', '.conda', 'weights-CNN.best.hdf5', 'kernel (1).ipynb', 'abc.ipynb', 'PatComboHalf.pickle', 'sorted_diagnoses.csv', 'PatReportMatrix.pickle', 'PatReportVectAverage.pickle', 'ir-project.ipynb', 'PatComboFull.pickle', '.ssh', 'patient_disease_vector.csv', 'mimic-300D-3.5M.bin.trainables.syn1neg.npy']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"text_cleaned.csv.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date discharge date service addendum...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date discharge date date birth sex f...</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date discharge date service cardioth...</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admission date discharge date service medicine...</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission date discharge date date birth sex s...</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  word_count\n",
       "0  admission date discharge date service addendum...          60\n",
       "1  admission date discharge date date birth sex f...        1034\n",
       "2  admission date discharge date service cardioth...         855\n",
       "3  admission date discharge date service medicine...        1474\n",
       "4  admission date discharge date date birth sex s...        1259"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./text_cleaned.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8dda09551c22db07ed688f880fc3a76626468426"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2083180,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file=df['TEXT'].values\n",
    "train_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c2cbed62434b97d8b593110389d6b9d33d3d9c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admission date discharge date date birth sex f service medicine history present illness female extensive history alcohol abuse class b child cirrhosis abstinent alcohol since saw primary care physician complaints history general malaise abdominal pain found white count notified three days thereafter told go emergency room presented emergency department abdominal pain hypotensive baseline systolic pressure responsive intravenous fluids started dopamine sent unit presentation white count total bilirubin urinalysis positive escherichia coli subsequent abdomen ultrasound showed ascites right upper quadrant ultrasound showed gallbladder inflammation consistent cholecystitis started ceftriaxone vancomycin flagyl endoscopic retrograde cholangiopancreatography ward name common bile duct stent transient elevation amylase lipase status post stent falling time transfer weaned pressors followed gastroenterology general surgery evening transfer medicine service tolerating solids without nausea vomiting nausea vomiting since admission hematocrit stable review systems negative history esophageal varices ii one grade esophagogastroduodenoscopy history upper gastrointestinal bleed hemodynamically stable pressors floor without problem past medical history alcoholic hepatitis cirrhosis child class b alcohol abuse history upper gastrointestinal bleed cholelithiasis gastroesophageal reflux disease anemia urinary tract infection hypercholesterolemia gastritis hip fracture social history lives sister un three sons half pack per day smoking absent alcohol since medications transfer neurontin mg ursodiol mg multivitamin thiamine folate ceftriaxone protonix toradol needed allergies allergy penicillin levofloxacin codeine medications home medications home include lasix thiamine folate multivitamin spironolactone neurontin mg propranolol mg ursodiol physical examination presentation vital signs revealed temperature blood pressure heart rate respiratory rate oxygen saturation room air acute distress mild scleral icterus neck supple without lymphadenopathy lungs clear heart revealed first heart sound second heart sound abdomen soft mildly tender guarding rebound positive bowel sounds liver enlarged extremities showed edema dorsalis pedis pulses radial pulses bilaterally right upper quadrant ultrasound showed gallbladder wall thickening common bile duct mm stones ct abdomen without contrast showed diverticula dilated bowel loops inflammation changes moderate ascites multiple subcentimeter mesenteric retroperitoneal lymphadenopathy nonspecific hospital course system gastrointestinal status post endoscopic retrograde cholangiopancreatography common bile duct stent stable time transfer medicine service remained stable throughout admission liver function tests total bilirubin still mildly evaluated time discharge follow endoscopic retrograde cholangiopancreatography fellow stent removal two three weeks status post discharge infectious disease treated ceftriaxone escherichia coli negative cultures otherwise treated total days given complicated urinary tract infection treated bactrim discharge diagnoses urinary tract infection complicated sepsis cholecystitis class b cirrhosis name stitle lf dictated name job number'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f40104bb51732f24d48f5c6347c603b7c6917862"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def data_list(big_list):\n",
    "    data_list=[]\n",
    "    for i in range(len(big_list)):\n",
    "        curr_string=str(big_list[i])\n",
    "        curr_string=curr_string.lower()\n",
    "        word_tokens = word_tokenize(curr_string)\n",
    "        data_list.append(word_tokens) \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4a501e61104bb06f06eaea0f5ff043d66f58ab9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strating\n",
      "Word2Vec(vocab=347113, size=300, alpha=0.025)\n",
      "347113\n",
      "[-1.3602095  -3.9968271  -3.569002   -0.09831091 -3.376415   -2.3465135\n",
      " -1.8254884   0.37712762 -1.8530942  -4.0837393   2.7218137   1.6821749\n",
      " -1.573987    0.5103347   0.03972801  2.8294103  -0.3880204   0.12649122\n",
      " -1.6709422  -3.1543174  -2.5914185   2.8972301  -1.9932123   0.77022225\n",
      " -2.8854449  -3.3123333  -0.156261   -0.2994684  -3.2708588   3.025939\n",
      " -1.1029148   0.25915602  3.4952962  -0.579748    0.4410795   3.2813609\n",
      " -0.7046842  -0.24219711  1.0056903  -2.2699847   2.2628531   1.5454738\n",
      " -0.12766461 -2.430933    0.24728878 -5.9576607   2.469833   -0.74131554\n",
      "  0.8932214   1.8288503   0.5567043   0.42554742  0.64279336  3.0933473\n",
      "  0.43160138  0.01678712  3.358536   -1.8507663   1.0828675  -2.091064\n",
      " -0.46389338  2.9369032   1.6309198   0.7936424  -2.9809077   0.67704165\n",
      "  3.29595    -4.076585   -3.6533484  -0.58955437 -2.6442525  -3.6278021\n",
      "  0.8872541  -1.9872634   0.06706046 -1.9831231  -0.36076048  1.2086655\n",
      "  2.7775874   0.20835847 -1.4040267   1.1865422  -1.3325126   0.10582425\n",
      " -0.95889527 -1.4141692  -1.6228294   2.9900942   1.6317182  -0.6615729\n",
      " -0.62267625  0.28752455 -2.2377527  -0.09504551 -0.762281   -1.0919948\n",
      "  0.6184031   0.60912246  0.37038174  4.6578603   3.542898   -1.7492783\n",
      "  1.4393772   0.9225877   0.2155702   0.7388346  -1.5770031   0.8790531\n",
      "  1.6307142   1.712221   -1.78623     1.420836    2.9313302  -3.9442623\n",
      "  1.3728864  -0.31446108 -1.8983076   5.0492015  -1.7621771  -0.20793355\n",
      "  2.0480077   0.6877566  -2.6553981  -0.9792476  -0.6206804  -1.4660568\n",
      "  2.907746    0.35752094 -2.2429848   5.4750094  -0.17672224 -1.0184546\n",
      "  3.5577714  -0.04347224 -0.47752312  2.2795885   0.6834849   0.2605932\n",
      "  1.0975013  -1.0767587   0.94902235 -2.8195014   0.6980703  -1.1068581\n",
      "  1.0720377  -1.7367054   0.80575633  0.87498176 -0.5056532   0.46814057\n",
      "  0.4649931  -0.18573616  3.7057078   1.4297061  -1.3592044   2.0413451\n",
      "  0.620944   -1.4711943   2.095613   -0.8472811   2.817244    2.0701492\n",
      " -0.42918572 -2.2265682   0.94316405  0.5529985  -0.27453932  1.4739661\n",
      " -1.6631593   1.1493214   0.23977654  1.5544946   2.5479057  -0.9620993\n",
      " -2.4930325   0.93701726 -2.11393    -5.3313794  -0.4365393   3.4983435\n",
      "  1.9476835  -1.906993    1.8485448   2.1831818   2.0772095   0.30230546\n",
      " -1.3116676   2.4729366  -3.546317   -1.1090641  -3.240204    0.5106414\n",
      " -3.2108495   0.78223884  2.70334     0.51064616 -0.94815195 -2.398093\n",
      "  4.3290486   2.2265627   4.7294126   0.52762824  1.3776517   1.4387245\n",
      "  2.3369725  -1.4466585  -0.13601616 -1.4665086  -1.6332027  -0.9431844\n",
      "  1.0466083  -1.6224333  -2.3948405   0.6904495   1.5369556   1.149387\n",
      "  0.02180262 -1.5452335   1.4817507  -0.8780173  -5.2167387  -1.443656\n",
      " -1.8192608  -1.4450067  -0.4215712   1.7417256  -0.4324891   1.2268958\n",
      " -1.2528684  -0.3615563  -1.2748339  -3.2753642   0.4900703  -1.2978162\n",
      "  0.3731887   3.8868034   1.5633625   0.28759888 -0.5352149  -3.0356734\n",
      " -3.2233531   2.1975212  -1.7370889  -1.5212598   2.0162852   1.6180857\n",
      "  3.0603158  -2.0720284  -2.3837652  -3.0968337   1.1344876   1.7541307\n",
      "  2.4470224  -1.003096   -2.3131335  -0.14582981 -0.9053314  -3.006723\n",
      "  0.18462197 -1.6402556   3.9938693  -0.73047477 -2.1282518   1.5751439\n",
      "  2.021522   -4.358879   -2.4424026   0.10363171  1.2532659   0.77921855\n",
      "  3.2888396   0.0890213   4.529366    0.32043123 -3.8422282   0.8427543\n",
      "  1.2240853   2.7101662  -1.8786974  -0.09297398  0.91875094  3.197446\n",
      " -0.338554    0.8560432   0.39926657  3.435251   -0.86460733 -1.3541081\n",
      " -0.8904217   2.1248007  -0.10496468 -1.6028928  -1.8593314  -0.3200609\n",
      "  1.0307071  -1.703637   -0.20905179  1.9284213   1.799665   -0.58160394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachiket/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=347113, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# train model\n",
    "new_list=data_list(train_file)\n",
    "print(\"Strating\")\n",
    "model = Word2Vec(new_list,size=300, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(len(words))\n",
    "# access vector for one word\n",
    "print(model['admission'])\n",
    "# save model\n",
    "model.save('mimic-300D-3.5M.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('mimic-300D-3.5M.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strating\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TaggedDocument' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2a1f2b8877f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2a1f2b8877f9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TaggedDocument' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec,TaggedDocument\n",
    "\n",
    "# train model\n",
    "new_list=data_list(train_file)\n",
    "print(\"Strating\")\n",
    "\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(new_list)]\n",
    "\n",
    "max_epochs = 100\n",
    "vec_size = 300\n",
    "alpha = 0.05\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.0003,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"Doc2Vec-300D-mimic.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5c025026a91d672dd05e295be6173ddffc7b9f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nachiket/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
